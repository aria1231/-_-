{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 85390,
          "databundleVersionId": 9871825,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30761,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "NCU_CE6020_Hw2_AutoEncoder_110403030",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aria1231/-_-/blob/main/NCU_CE6020_Hw2_AutoEncoder_110403030.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "Ff_hgdBIcphJ"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "reconstructing_stock_time_series_data_using_autoen_path = kagglehub.competition_download('reconstructing-stock-time-series-data-using-autoen')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Rc-iQrjlcphL"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Package\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "seed = 6020\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Sklearn Package\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "\n",
        "# Torch Package\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Plotly\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:21.941606Z",
          "iopub.execute_input": "2024-10-25T18:13:21.942138Z",
          "iopub.status.idle": "2024-10-25T18:13:21.950495Z",
          "shell.execute_reply.started": "2024-10-25T18:13:21.942093Z",
          "shell.execute_reply": "2024-10-25T18:13:21.949252Z"
        },
        "trusted": true,
        "id": "S0aUavsKcphL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data."
      ],
      "metadata": {
        "id": "2H0KxBDScphL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Path.\n",
        "training_data_path = \"/kaggle/input/reconstructing-stock-time-series-data-using-autoen/train.csv\"\n",
        "testing_data_path = \"/kaggle/input/reconstructing-stock-time-series-data-using-autoen/test.csv\"\n",
        "\n",
        "# Read Data.\n",
        "ori_training_data = pd.read_csv(training_data_path, index_col='id')\n",
        "ori_testing_data = pd.read_csv(testing_data_path, index_col='id')\n",
        "\n",
        "# Sort Data\n",
        "ori_training_data = ori_training_data.sort_values(by=['stock_id', 'date'], ascending=[True, True])\n",
        "ori_testing_data = ori_testing_data.sort_values(by=['stock_id', 'date'], ascending=[True, True])\n",
        "\n",
        "print(f\"The data columns length: {len(ori_training_data.columns.values)}\")\n",
        "print(f\"The training data shape: {ori_training_data.shape}\")\n",
        "print(f\"The testing data shape: {ori_testing_data.shape}\")\n",
        "\n",
        "ori_training_data.head(3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:21.952641Z",
          "iopub.execute_input": "2024-10-25T18:13:21.953257Z",
          "iopub.status.idle": "2024-10-25T18:13:22.484106Z",
          "shell.execute_reply.started": "2024-10-25T18:13:21.953199Z",
          "shell.execute_reply": "2024-10-25T18:13:22.48286Z"
        },
        "trusted": true,
        "id": "B12WeC_JcphM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.line(ori_training_data, x='date', y='close', color='stock_id', title=\"Stock Close Prices Over Time\")\n",
        "fig.update_layout(\n",
        "    title={'text': \"Stock Close Prices Over Time (Training Data)\", 'font': {'size': 30}},\n",
        "    xaxis_title={'text': \"Date\", 'font': {'size': 20}},\n",
        "    yaxis_title={'text': \"Close Price\", 'font': {'size': 18}},\n",
        "    xaxis={'tickfont': {'size': 15}},\n",
        "    yaxis={'tickfont': {'size': 14}},\n",
        "    legend={'font': {'size': 18}}\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:22.486011Z",
          "iopub.execute_input": "2024-10-25T18:13:22.486439Z",
          "iopub.status.idle": "2024-10-25T18:13:22.621208Z",
          "shell.execute_reply.started": "2024-10-25T18:13:22.486394Z",
          "shell.execute_reply": "2024-10-25T18:13:22.619974Z"
        },
        "trusted": true,
        "id": "yqVTSm7ycphM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the first 5 rows of the testing data with missing 'close' values or 'open' values.\n",
        "missing_data = ori_testing_data[ori_testing_data[\"close\"].isna() | ori_testing_data[\"open\"].isna()]\n",
        "print(f\"How much missing value:\", len(missing_data))\n",
        "fig = px.line(ori_testing_data, x='date', y='close', color='stock_id', title=\"Stock Close Prices Over Time\")\n",
        "fig.update_layout(\n",
        "    title={'text': \"Stock Close Prices Over Time (Testing Data)\", 'font': {'size': 30}},\n",
        "    xaxis_title={'text': \"Date\", 'font': {'size': 20}},\n",
        "    yaxis_title={'text': \"Close Price\", 'font': {'size': 18}},\n",
        "    xaxis={'tickfont': {'size': 15}},\n",
        "    yaxis={'tickfont': {'size': 14}},\n",
        "    legend={'font': {'size': 18}}\n",
        ")\n",
        "fig.show()\n",
        "missing_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:22.62456Z",
          "iopub.execute_input": "2024-10-25T18:13:22.625057Z",
          "iopub.status.idle": "2024-10-25T18:13:22.802696Z",
          "shell.execute_reply.started": "2024-10-25T18:13:22.625001Z",
          "shell.execute_reply": "2024-10-25T18:13:22.801183Z"
        },
        "trusted": true,
        "id": "tiUOi5i7cphM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Target\n",
        "\n",
        "- Task: Train an AutoEncoder model to restore missing data in the test set.\n",
        "- Data: The training data consists of 1862 days of complete daily stock information; the test set consists of 233 days of daily stock information, with some missing data.\n",
        "- Description: Use the training data to train the model, then apply the model to restore the missing data in the test set. Evaluate the model's restoration performance and accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "Tzr3-l94cphM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PreProcess"
      ],
      "metadata": {
        "id": "NyLOswzLcphN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare features\n",
        "main_features = [\"date\", \"stock_id\"]\n",
        "output_features = [\"close\", \"open\"]\n",
        "input_features = [feature for feature in ori_training_data.columns if feature not in main_features + output_features]\n",
        "\n",
        "features = input_features + output_features\n",
        "all_features = main_features + features\n",
        "\n",
        "training_data = ori_training_data[all_features].copy()\n",
        "testing_data = ori_testing_data[all_features].copy()\n",
        "\n",
        "# Encode 'stock_id' with LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "training_data['stock_id_encoded'] = label_encoder.fit_transform(training_data['stock_id'])\n",
        "testing_data['stock_id_encoded'] = label_encoder.transform(testing_data['stock_id'])\n",
        "stock_ids = training_data['stock_id_encoded'].unique()\n",
        "\n",
        "# Store mapping for inverse transformation\n",
        "stock_id_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
        "\n",
        "# Drop 'stock_id' column\n",
        "training_data.drop(['stock_id'], axis=1, inplace=True)\n",
        "testing_data.drop(['stock_id'], axis=1, inplace=True)\n",
        "\n",
        "# Sort data by 'stock_id_encoded' and 'date' to maintain temporal order per stock\n",
        "training_data.sort_values(['stock_id_encoded', 'date'], inplace=True)\n",
        "testing_data.sort_values(['stock_id_encoded', 'date'], inplace=True)\n",
        "\n",
        "print(f\"The stock encoded mapping: {stock_id_mapping}\")\n",
        "training_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:22.804654Z",
          "iopub.execute_input": "2024-10-25T18:13:22.80523Z",
          "iopub.status.idle": "2024-10-25T18:13:22.880646Z",
          "shell.execute_reply.started": "2024-10-25T18:13:22.805163Z",
          "shell.execute_reply": "2024-10-25T18:13:22.879371Z"
        },
        "trusted": true,
        "id": "3djN-kAhcphN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mask"
      ],
      "metadata": {
        "id": "mImSlfVLcphN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! Adjust this method if needed.\n",
        "def sample_stock_data(data, stock_ids, samples_per_stock, seed=None, limit_column='id', start_index=0):\n",
        "    sampled_data = pd.DataFrame()\n",
        "\n",
        "    if seed is not None: np.random.seed(seed)\n",
        "    for stock_id in stock_ids:\n",
        "        stock_data = data[(data['stock_id_encoded'] == stock_id) & (data[limit_column] >= start_index)]\n",
        "        if len(stock_data) < samples_per_stock:\n",
        "            sampled_data = pd.concat([sampled_data, stock_data])\n",
        "        else:\n",
        "            sampled_data = pd.concat([sampled_data, stock_data.sample(n=samples_per_stock, replace=False)])\n",
        "    return sampled_data\n",
        "\n",
        "def mask_sample_stock_data(data, sample_mask_data):\n",
        "    mask_indices = sample_mask_data.index\n",
        "    masked_data = data.copy()\n",
        "    masked_data.loc[mask_indices, ['open', 'close']] = np.nan\n",
        "\n",
        "    mask = (~masked_data[features].isna()).astype(float)\n",
        "\n",
        "    return masked_data, mask\n",
        "\n",
        "samples_per_stock = 185 #! Adjust this value if needed.\n",
        "unique_stock_ids = training_data['stock_id_encoded'].unique()\n",
        "sample_mask_training_data = sample_stock_data(training_data, unique_stock_ids, samples_per_stock, seed=seed, limit_column='date', start_index=30)\n",
        "mask_training_data, mask_training_features = mask_sample_stock_data(training_data, sample_mask_training_data)\n",
        "\n",
        "# Reading the training data with the mask.\n",
        "missing_data = mask_training_data[mask_training_data[\"close\"].isna() | mask_training_data[\"open\"].isna()]\n",
        "print(f\"How much missing value:\", len(missing_data))\n",
        "fig = px.line(mask_training_data, x='date', y='close', color='stock_id_encoded', title=\"Stock Close Prices Over Time\")\n",
        "fig.update_layout(\n",
        "    title={'text': \"Stock Close Prices Over Time (Training Data with MASK)\", 'font': {'size': 30}},\n",
        "    xaxis_title={'text': \"Date\", 'font': {'size': 20}},\n",
        "    yaxis_title={'text': \"Close Price\", 'font': {'size': 18}},\n",
        "    xaxis={'tickfont': {'size': 15}},\n",
        "    yaxis={'tickfont': {'size': 14}},\n",
        "    legend={'font': {'size': 18}}\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "# missing_data\n",
        "mask_training_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:22.882567Z",
          "iopub.execute_input": "2024-10-25T18:13:22.882934Z",
          "iopub.status.idle": "2024-10-25T18:13:23.098042Z",
          "shell.execute_reply.started": "2024-10-25T18:13:22.882895Z",
          "shell.execute_reply": "2024-10-25T18:13:23.096848Z"
        },
        "trusted": true,
        "id": "1kIhEup3cphN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scale\n"
      ],
      "metadata": {
        "id": "j3aZs4rMcphN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare features\n",
        "train_features = training_data[features]\n",
        "mask_train_features = mask_training_data[features]\n",
        "test_features = testing_data[features]\n",
        "\n",
        "# Fit scaler on training data and transform both training and testing data, to 0-1\n",
        "scaler = MinMaxScaler()\n",
        "train_scaler = scaler.fit_transform(training_data[features])\n",
        "mask_train_scaled = scaler.transform(mask_training_data[features])\n",
        "test_scaled = scaler.transform(testing_data[features])\n",
        "\n",
        "# Replace the original features in the data with the scaled features\n",
        "training_data_scaled = training_data.copy()\n",
        "mask_training_data_scaled = mask_training_data.copy()\n",
        "testing_data_scaled = testing_data.copy()\n",
        "\n",
        "training_data_scaled[features] = train_scaler\n",
        "mask_training_data_scaled[features] = mask_train_scaled\n",
        "testing_data_scaled[features] = test_scaled\n",
        "\n",
        "print(f\"Training data with scaling: {training_data_scaled.shape}\")\n",
        "print(f\"Training data with scaling: {mask_training_data_scaled.shape}\")\n",
        "print(f\"Testing data with scaling: {testing_data_scaled.shape}\")\n",
        "\n",
        "training_data_scaled.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:23.099478Z",
          "iopub.execute_input": "2024-10-25T18:13:23.099908Z",
          "iopub.status.idle": "2024-10-25T18:13:23.248018Z",
          "shell.execute_reply.started": "2024-10-25T18:13:23.099865Z",
          "shell.execute_reply": "2024-10-25T18:13:23.246663Z"
        },
        "trusted": true,
        "id": "sG513OiNcphN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequences"
      ],
      "metadata": {
        "id": "BsQjkOxNcphN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define sequence length #! Adjust this value if needed.\n",
        "sequence_length = 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:23.249739Z",
          "iopub.execute_input": "2024-10-25T18:13:23.250163Z",
          "iopub.status.idle": "2024-10-25T18:13:23.255603Z",
          "shell.execute_reply.started": "2024-10-25T18:13:23.250118Z",
          "shell.execute_reply": "2024-10-25T18:13:23.254269Z"
        },
        "trusted": true,
        "id": "xQjVjCnGcphN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(data, masks, sequence_length, indices):\n",
        "    sequences = []\n",
        "    mask_sequences = []\n",
        "    seq_indices = []\n",
        "    for i in range(len(data) - sequence_length + 1):\n",
        "        sequences.append(data[i:i + sequence_length])\n",
        "        mask_sequences.append(masks[i:i + sequence_length])\n",
        "        seq_indices.append(indices[i + sequence_length - 1])  # Index of the last time step\n",
        "    return np.array(sequences), np.array(mask_sequences), np.array(seq_indices)\n",
        "\n",
        "\n",
        "# Create sequences for training and testing data considering different stock_id\n",
        "train_sequences = []\n",
        "mask_train_sequences = []\n",
        "test_sequences = []\n",
        "test_sequence_indices = []\n",
        "\n",
        "# If you want to split the model for different stock_id, you can use this.\n",
        "different_stock_train_sequences = {stock_id: None for stock_id in stock_ids}\n",
        "different_stock_mask_train_sequences = {stock_id: None for stock_id in stock_ids}\n",
        "different_stock_test_sequences = {stock_id: None for stock_id in stock_ids}\n",
        "\n",
        "for stock_id in stock_ids:\n",
        "    # train\n",
        "    stock_train_indices = training_data_scaled[training_data_scaled['stock_id_encoded'] == stock_id].index.values\n",
        "    stock_train_data = training_data_scaled[training_data_scaled['stock_id_encoded'] == stock_id][features].values\n",
        "    stock_mask_train_data = mask_training_data_scaled[mask_training_data_scaled['stock_id_encoded'] == stock_id][features ].values\n",
        "    train_current_sequence, mask_train_current_sequence, train_seq_indices = create_sequences(stock_train_data, stock_mask_train_data, sequence_length, stock_train_indices)\n",
        "\n",
        "    different_stock_train_sequences[stock_id] = train_current_sequence\n",
        "    different_stock_mask_train_sequences[stock_id] = mask_train_current_sequence\n",
        "\n",
        "    train_sequences.extend(train_current_sequence)\n",
        "    mask_train_sequences.extend(mask_train_current_sequence)\n",
        "\n",
        "    # test\n",
        "    stock_test_indices = testing_data_scaled[testing_data_scaled['stock_id_encoded'] == stock_id].index.values\n",
        "    stock_test_data = testing_data_scaled[testing_data_scaled['stock_id_encoded'] == stock_id][features].values\n",
        "    stock_test_mask = np.ones_like(stock_test_data)\n",
        "    test_current_sequence, _, test_seq_indices = create_sequences(stock_test_data, stock_test_mask, sequence_length, stock_test_indices)\n",
        "\n",
        "    different_stock_test_sequences[stock_id] = test_current_sequence\n",
        "    test_sequences.extend(test_current_sequence)\n",
        "    test_sequence_indices.extend(test_seq_indices)\n",
        "    print(f\"Stock id: {stock_id}, Train sequences shape: {mask_train_current_sequence.shape} | Stock id: {stock_id}, Test sequences shape: {test_current_sequence.shape}\")\n",
        "\n",
        "train_sequences = np.array(train_sequences)\n",
        "mask_train_sequences = np.array(mask_train_sequences)\n",
        "test_sequences = np.array(test_sequences)\n",
        "print(f\"Train sequences shape: {mask_train_sequences.shape} | Test sequences shape: {test_sequences.shape}\") # 14864 = 14896 - 4 * 8\n",
        "\n",
        "train_sequences_flat = np.array(train_sequences).reshape(len(train_sequences), -1)\n",
        "mask_train_sequences_flat = np.array(mask_train_sequences).reshape(len(mask_train_sequences), -1)\n",
        "test_sequences_flat = np.array(test_sequences).reshape(len(test_sequences), -1)\n",
        "print(f\"Train sequences flat shape: {mask_train_sequences_flat.shape} | Test sequences flat shape: {test_sequences_flat.shape}\")"
      ],
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:23.257706Z",
          "iopub.execute_input": "2024-10-25T18:13:23.258151Z",
          "iopub.status.idle": "2024-10-25T18:13:23.863463Z",
          "shell.execute_reply.started": "2024-10-25T18:13:23.258101Z",
          "shell.execute_reply": "2024-10-25T18:13:23.862234Z"
        },
        "trusted": true,
        "id": "5ysrDILccphO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "T4JmX6CWcphO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "mask_training_model_flat, mask_val_model_flat = train_test_split(mask_train_sequences_flat, test_size=0.2, shuffle=False)\n",
        "training_model_flat, val_model_flat = train_test_split(train_sequences_flat, test_size=0.2, shuffle=False)\n",
        "print(f\"Mask train sequences flat shape: {mask_training_model_flat.shape}\")\n",
        "print(f\"Mask validation sequences flat shape: {mask_val_model_flat.shape}\")\n",
        "\n",
        "print(f\"Train sequences flat shape: {training_model_flat.shape}\")\n",
        "print(f\"Validation sequences flat shape: {val_model_flat.shape}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:23.867351Z",
          "iopub.execute_input": "2024-10-25T18:13:23.867786Z",
          "iopub.status.idle": "2024-10-25T18:13:23.919079Z",
          "shell.execute_reply.started": "2024-10-25T18:13:23.86774Z",
          "shell.execute_reply": "2024-10-25T18:13:23.917287Z"
        },
        "trusted": true,
        "id": "WGOYwUwbcphO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "gOdEBS7ucphO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:23.920639Z",
          "iopub.execute_input": "2024-10-25T18:13:23.921079Z",
          "iopub.status.idle": "2024-10-25T18:13:23.927998Z",
          "shell.execute_reply.started": "2024-10-25T18:13:23.921027Z",
          "shell.execute_reply": "2024-10-25T18:13:23.926752Z"
        },
        "trusted": true,
        "id": "QTCh2cNbcphO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#! Adjust this Model if needed.\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim=64, dropout_prob=0.2):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.Dropout(dropout_prob),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.Dropout(dropout_prob),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(True),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.Dropout(dropout_prob),\n",
        "            nn.Linear(128, embedding_dim),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, 128),\n",
        "            nn.ReLU(True),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.Dropout(dropout_prob),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.Dropout(dropout_prob),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.Dropout(dropout_prob),\n",
        "            nn.Linear(512, input_dim),\n",
        "            nn.Sigmoid()  # Since data is scaled between 0 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:23.930021Z",
          "iopub.execute_input": "2024-10-25T18:13:23.930563Z",
          "iopub.status.idle": "2024-10-25T18:13:23.946702Z",
          "shell.execute_reply.started": "2024-10-25T18:13:23.930503Z",
          "shell.execute_reply": "2024-10-25T18:13:23.945283Z"
        },
        "trusted": true,
        "id": "iHK4JMYJcphO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"class LSTMAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, embedding_dim=64, num_layers=1, dropout_prob=0.2):\n",
        "        super(LSTMAutoencoder, self).__init__()\n",
        "\n",
        "        # Encoder LSTM\n",
        "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_prob)\n",
        "        self.encoder_fc = nn.Linear(hidden_dim, embedding_dim)  # 壓縮隱藏向量\n",
        "\n",
        "        # Decoder LSTM\n",
        "        self.decoder_fc = nn.Linear(embedding_dim, hidden_dim)\n",
        "        self.decoder = nn.LSTM(hidden_dim, input_dim, num_layers, batch_first=True, dropout=dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedding = self.encoder(x)\n",
        "\n",
        "        hidden = self.decoder_fc(embedding).unsqueeze(0).repeat(self.decoder.num_layers, 1, 1)  # [num_layers, batch_size, hidden_dim]\n",
        "        c_0 = torch.zeros(self.decoder.num_layers, x.size(0), hidden_dim).to(x.device)\n",
        "\n",
        "        output, _ = self.decoder(hidden.transpose(0, 1), (hidden, c_0))\n",
        "        return output\"\"\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:23.948533Z",
          "iopub.execute_input": "2024-10-25T18:13:23.949048Z",
          "iopub.status.idle": "2024-10-25T18:13:23.96525Z",
          "shell.execute_reply.started": "2024-10-25T18:13:23.948998Z",
          "shell.execute_reply": "2024-10-25T18:13:23.963977Z"
        },
        "trusted": true,
        "id": "qyXGe9g7cphO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper Parameters"
      ],
      "metadata": {
        "id": "7n2jAeG7cphO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters #! Adjust this value if needed.\n",
        "embedding_dim = 32\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001\n",
        "input_dim = sequence_length * len(features)\n",
        "\n",
        "model = Autoencoder(input_dim=input_dim, embedding_dim=embedding_dim).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.9)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:23.966956Z",
          "iopub.execute_input": "2024-10-25T18:13:23.967487Z",
          "iopub.status.idle": "2024-10-25T18:13:23.995635Z",
          "shell.execute_reply.started": "2024-10-25T18:13:23.967429Z",
          "shell.execute_reply": "2024-10-25T18:13:23.994143Z"
        },
        "trusted": true,
        "id": "Jq62CIb7cphO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Ici2kbBCcphP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create masks indicating missing positions (1 where data is missing)\n",
        "train_masks_flat = np.where(np.isnan(mask_training_model_flat), 1, 0)\n",
        "val_masks_flat = np.where(np.isnan(mask_val_model_flat), 1, 0)\n",
        "\n",
        "# Prepare tensors\n",
        "X_train_tensor = torch.tensor(np.nan_to_num(mask_training_model_flat, nan=0.0), dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(training_model_flat, dtype=torch.float32).to(device)  # Targets without NaNs\n",
        "mask_train_tensor = torch.tensor(train_masks_flat, dtype=torch.float32).to(device)\n",
        "\n",
        "X_val_tensor = torch.tensor(np.nan_to_num(mask_val_model_flat, nan=0.0), dtype=torch.float32).to(device)\n",
        "y_val_tensor = torch.tensor(val_model_flat, dtype=torch.float32).to(device)\n",
        "mask_val_tensor = torch.tensor(val_masks_flat, dtype=torch.float32).to(device)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor, mask_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor, mask_val_tensor)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize lists to store losses and NaN fill quality metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "nan_fill_quality_train = []\n",
        "nan_fill_quality_val = []\n",
        "\n",
        "# Define the loss function that ignores NaNs  #! Adjust this value if needed.\n",
        "def masked_loss_function(output, target, mask_missing, mask_weight=2.0):\n",
        "    loss = torch.abs(output - target)\n",
        "    weighted_loss = loss * (1 + mask_missing * (mask_weight - 1)) # Apply a higher weight to the missing data.\n",
        "    return weighted_loss.mean()\n",
        "\n",
        "\n",
        "# Define a function to evaluate the quality of NaN value reconstruction\n",
        "# This function computes the MAE (Mean Absolute Error) only for the positions where the values were originally NaN\n",
        "def evaluate_nan_fill_quality_mae(reconstructed, original, mask):\n",
        "    nan_mask = 1 - mask  # Get mask for NaN values\n",
        "    mae_nan_only = torch.abs(reconstructed - original) * nan_mask\n",
        "    mae_nan_only = mae_nan_only.sum() / nan_mask.sum()  # Normalize over the NaN values\n",
        "    return mae_nan_only\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    nan_fill_mae_train = 0\n",
        "    for inputs, targets, masks in train_loader:\n",
        "        outputs = model(inputs)\n",
        "        loss = masked_loss_function(outputs, targets, masks)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calculate the MAE for NaN filled values during training\n",
        "        nan_mae = evaluate_nan_fill_quality_mae(outputs, targets, masks)\n",
        "        nan_fill_mae_train += nan_mae.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    avg_nan_fill_mae_train = nan_fill_mae_train / len(train_loader)\n",
        "    train_losses.append(avg_loss)\n",
        "    nan_fill_quality_train.append(avg_nan_fill_mae_train)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    nan_fill_mae_val = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets, masks in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = masked_loss_function(outputs, targets, masks)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate the MAE for NaN filled values during validation\n",
        "            nan_mae_val = evaluate_nan_fill_quality_mae(outputs, targets, masks)\n",
        "            nan_fill_mae_val += nan_mae_val.item()\n",
        "\n",
        "    # Compute the average validation loss and NaN MAE for the current epoch\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    avg_nan_fill_mae_val = nan_fill_mae_val / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    nan_fill_quality_val.append(avg_nan_fill_mae_val)\n",
        "\n",
        "    # Step the learning rate scheduler at the end of each epoch\n",
        "    scheduler.step()\n",
        "\n",
        "    # Print losses and learning rate every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        print(f\"Loss: {avg_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
        "        print(f\"Train NaN Fill MAE: {avg_nan_fill_mae_train:.6f}, Val NaN Fill MAE: {avg_nan_fill_mae_val:.6f}\")\n",
        "        print(f\"Current learning rate: {scheduler.get_last_lr()}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:13:23.997298Z",
          "iopub.execute_input": "2024-10-25T18:13:23.997824Z",
          "iopub.status.idle": "2024-10-25T18:17:36.613537Z",
          "shell.execute_reply.started": "2024-10-25T18:13:23.997757Z",
          "shell.execute_reply": "2024-10-25T18:17:36.612219Z"
        },
        "trusted": true,
        "id": "u0wB-uItcphP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "# Training Loss\n",
        "fig.add_trace(go.Scatter(x=list(range(num_epochs)), y=train_losses, mode='lines', name='Training Loss'))\n",
        "\n",
        "# Validation Loss\n",
        "fig.add_trace(go.Scatter(x=list(range(num_epochs)), y=val_losses, mode='lines', name='Validation Loss'))\n",
        "\n",
        "# Update layout for the plot\n",
        "fig.update_layout(\n",
        "    title='Training and Validation Loss over Epochs',\n",
        "    xaxis_title='Epoch',\n",
        "    yaxis_title='Loss',\n",
        "    legend=dict(x=0.8, y=1),\n",
        "    autosize=False,\n",
        "    width=1200,\n",
        "    height=500,\n",
        "    xaxis=dict(range=[-5, num_epochs + 5]), # Make some space on the left and right\n",
        "\n",
        "    # For the font size\n",
        "    font=dict(size=18),\n",
        "    title_font=dict(size=24),\n",
        "    xaxis_title_font=dict(size=20),\n",
        "    yaxis_title_font=dict(size=20)\n",
        ")\n",
        "\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:17:36.615129Z",
          "iopub.execute_input": "2024-10-25T18:17:36.61559Z",
          "iopub.status.idle": "2024-10-25T18:17:36.652217Z",
          "shell.execute_reply.started": "2024-10-25T18:17:36.615545Z",
          "shell.execute_reply": "2024-10-25T18:17:36.650902Z"
        },
        "trusted": true,
        "id": "50_TtRjecphP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "K1EhCFL5cphP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert testing sequences to PyTorch tensor\n",
        "test_masks_flat = np.where(np.isnan(test_sequences_flat), 1, 0)   # Set non-NaN values to 1, NaN values to 0\n",
        "X_test_tensor = torch.tensor(np.nan_to_num(test_sequences_flat, nan=0.0), dtype=torch.float32).to(device)\n",
        "mask_test_tensor = torch.tensor(test_masks_flat, dtype=torch.float32).to(device)      # Mask tensor\n",
        "\n",
        "# Reconstruct the sequences\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    reconstructed = model(X_test_tensor).cpu().numpy()\n",
        "\n",
        "# Reshape reconstructed data back to (num_samples, seq_length, n_features)\n",
        "reconstructed_sequences = reconstructed.reshape(-1, sequence_length, len(features))\n",
        "\n",
        "# Extract the last time step for each sequence\n",
        "reconstructed_last_steps = reconstructed_sequences[:, -1, :]  # Shape: (num_samples, n_features)\n",
        "\n",
        "# Map reconstructed data back to original scale\n",
        "reconstructed_last_steps_inversed = scaler.inverse_transform(reconstructed_last_steps)\n",
        "\n",
        "# Prepare DataFrame with correct indices\n",
        "reconstructed_df = pd.DataFrame(reconstructed_last_steps_inversed, columns=features, index=test_sequence_indices)\n",
        "print(f\"Shape of test sequences: {test_sequences_flat.shape}\")\n",
        "\n",
        "reconstructed_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:17:36.653635Z",
          "iopub.execute_input": "2024-10-25T18:17:36.654033Z",
          "iopub.status.idle": "2024-10-25T18:17:36.797486Z",
          "shell.execute_reply.started": "2024-10-25T18:17:36.653989Z",
          "shell.execute_reply": "2024-10-25T18:17:36.796264Z"
        },
        "trusted": true,
        "id": "VLxKNXSWcphP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the testing missing indices\n",
        "filled_testing_data = testing_data.copy()\n",
        "missing_indices = filled_testing_data[(filled_testing_data['close'].isna()) | (filled_testing_data['open'].isna())].index\n",
        "\n",
        "for idx in missing_indices:\n",
        "    if idx in reconstructed_df.index:\n",
        "        if pd.isna(filled_testing_data.at[idx, 'close']):\n",
        "            filled_testing_data.at[idx, 'close'] = reconstructed_df.at[idx, 'close']\n",
        "        if pd.isna(filled_testing_data.at[idx, 'open']):\n",
        "            filled_testing_data.at[idx, 'open'] = reconstructed_df.at[idx, 'open']\n",
        "    else:\n",
        "        # Handle cases where index is not in reconstructed_df\n",
        "        mean_values = reconstructed_df[output_features].mean()\n",
        "        if pd.isna(filled_testing_data.at[idx, 'close']):\n",
        "            filled_testing_data.at[idx, 'close'] = mean_values['close']\n",
        "        if pd.isna(filled_testing_data.at[idx, 'open']):\n",
        "            filled_testing_data.at[idx, 'open'] = mean_values['open']\n",
        "\n",
        "# Check for remaining missing values\n",
        "remaining_missing = filled_testing_data[(filled_testing_data['close'].isna()) | (filled_testing_data['open'].isna())]\n",
        "print(f\"Number of remaining missing values: {len(remaining_missing)}\")\n",
        "if not remaining_missing.empty:\n",
        "    print(\"Remaining missing data:\")\n",
        "    print(remaining_missing.head())\n",
        "else:\n",
        "    print(\"All missing values have been successfully filled.\")\n",
        "\n",
        "filled_testing_data.loc[missing_indices]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:17:36.799324Z",
          "iopub.execute_input": "2024-10-25T18:17:36.799899Z",
          "iopub.status.idle": "2024-10-25T18:17:36.915642Z",
          "shell.execute_reply.started": "2024-10-25T18:17:36.799842Z",
          "shell.execute_reply": "2024-10-25T18:17:36.914392Z"
        },
        "trusted": true,
        "id": "X1VeA1WkcphP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output"
      ],
      "metadata": {
        "id": "PfbTzCkncphP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map 'stock_id_encoded' back to 'stock_id'\n",
        "filled_testing_data['stock_id'] = filled_testing_data['stock_id_encoded'].map(stock_id_mapping)\n",
        "reconstructed_df['stock_id'] = filled_testing_data['stock_id']\n",
        "reconstructed_df['date'] = filled_testing_data['date']\n",
        "reconstructed_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:17:36.917143Z",
          "iopub.execute_input": "2024-10-25T18:17:36.917598Z",
          "iopub.status.idle": "2024-10-25T18:17:36.963037Z",
          "shell.execute_reply.started": "2024-10-25T18:17:36.917554Z",
          "shell.execute_reply": "2024-10-25T18:17:36.961757Z"
        },
        "trusted": true,
        "id": "O9yrbdjzcphP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the filled 'close' prices\n",
        "fig = px.line(filled_testing_data, x='date', y='close', color='stock_id', title=\"Filled Testing Data: Stock Close Prices Over Time\")\n",
        "fig.show()\n",
        "\n",
        "fig = px.line(reconstructed_df, x='date', y='close', color='stock_id', title=\"Reconstructed: Stock Close Prices Over Time\")\n",
        "fig.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:17:36.965086Z",
          "iopub.execute_input": "2024-10-25T18:17:36.96553Z",
          "iopub.status.idle": "2024-10-25T18:17:37.191341Z",
          "shell.execute_reply.started": "2024-10-25T18:17:36.965483Z",
          "shell.execute_reply": "2024-10-25T18:17:37.190023Z"
        },
        "trusted": true,
        "id": "M5YKqgTRcphQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select columns and set index name\n",
        "result = filled_testing_data[['open', 'close']]\n",
        "result.index.name = 'id'\n",
        "result = result.sort_index()\n",
        "\n",
        "# Save the result to a CSV file\n",
        "result.to_csv(\"/kaggle/working/sample_submission.csv\")\n",
        "result"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-25T18:17:37.193048Z",
          "iopub.execute_input": "2024-10-25T18:17:37.193526Z",
          "iopub.status.idle": "2024-10-25T18:17:37.229388Z",
          "shell.execute_reply.started": "2024-10-25T18:17:37.19348Z",
          "shell.execute_reply": "2024-10-25T18:17:37.228063Z"
        },
        "trusted": true,
        "id": "tFNVqgn0cphQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "a_37Ace_cphQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}